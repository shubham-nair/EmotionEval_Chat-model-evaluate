import openai
import os
import json
import time
from openai import OpenAI
import os
from openai import OpenAI

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def format_prompt(context, response):
    return f"""ç”¨æˆ·è¾“å…¥ï¼šâ€œ{context}â€
æœºå™¨äººå›å¤ï¼šâ€œ{response}â€

è¯·æŒ‰ä»¥ä¸‹ä¸‰ä¸ªç»´åº¦ä¸ºæœºå™¨äººçš„å›å¤æ‰“åˆ†ï¼ˆæ¯é¡¹ 0~5 åˆ†ï¼‰ï¼š
1. å›å¤æ˜¯å¦æµç•…è‡ªç„¶ï¼ˆfluencyï¼‰ï¼Ÿ
2. å›å¤æ˜¯å¦ä¸ç”¨æˆ·è¾“å…¥ç›¸å…³ï¼ˆrelevanceï¼‰ï¼Ÿ
3. å›å¤æ˜¯å¦åƒäººç±»è€Œéæœºå™¨äººæ‰€è¯´ï¼ˆhumannessï¼‰ï¼Ÿ

è¯·ç›´æ¥è¾“å‡ºæ ‡å‡† JSON æ ¼å¼ï¼š
{{"fluency": 4.8, "relevance": 4.5, "humanness": 4.6}}"""

def gpt_score(prompt, model="gpt-4"):
    for attempt in range(3):
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2
            )
            text = response.choices[0].message.content
            return json.loads(text)
        except Exception as e:
            print(f"é‡è¯•ä¸­ï¼ˆç¬¬{attempt+1}æ¬¡ï¼‰... é”™è¯¯ï¼š{e}")
            time.sleep(2)
    return {"fluency": 0, "relevance": 0, "humanness": 0}

def eval_fed(data):
    results = []
    for item in data:
        prompt = format_prompt(item["context"], item["response"])
        scores = gpt_score(prompt)
        results.append({
            "session_id": item["session_id"],
            "model_version": item.get("model_version", "unknown"),  # ğŸ”§ åŠ å…¥æ¨¡å‹ç‰ˆæœ¬å­—æ®µ
            **scores
        })
    return results

