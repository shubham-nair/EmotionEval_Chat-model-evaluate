from data_loader_chatlogs import load_data
from eval_fed_gpt import eval_fed
import pandas as pd

def compare_scores_inline():
    # 1. åŠ è½½èŠå¤©è®°å½•ï¼ˆæ¯æ¡åŒ…å« session_id, context, response, model_versionï¼‰
    data = load_data()

    # 2. GPT è¯„åˆ†
    scores = eval_fed(data)

    # 3. è½¬ä¸º DataFrame
    df = pd.DataFrame(scores)

    # 4. åˆ†ç»„å¯¹æ¯”æ¨¡å‹å¹³å‡å¾—åˆ†
    grouped = df.groupby("model_version")[["fluency", "relevance", "humanness"]].mean().round(2)
    grouped["count"] = df.groupby("model_version").size()

    # 5. æ‰“å°æ¯æ¡åŸå§‹è¯„åˆ†
    print("\nğŸ¯ æ¯æ¡è¯„åˆ†ç»“æœï¼š")
    print(df.to_markdown(index=False))

    # 6. æ‰“å°æ¨¡å‹å¯¹æ¯”ç»“æœ
    print("\nâœ… æ¨¡å‹å¹³å‡è¯„åˆ†å¯¹æ¯”ï¼š\n")
    print(grouped.reset_index().to_markdown(index=False))

    # å¯é€‰ï¼šä¿å­˜ä¸º CSVï¼ˆå¦‚ä»æƒ³ä¿ç•™ï¼‰
    # df.to_csv("scored_chat_logs.csv", index=False)
    # grouped.to_csv("model_comparison.csv")

if __name__ == "__main__":
    compare_scores_inline()
